{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text ming, feature creation and classification of federal government (USA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The USA has a wealth of documents released by the various department through white houe. These documents are stored in the  database of the \"Federal Registry\". The documents are available from Bill Clinton tenure till date. This study solely focuses on the \"Final ruling\" document issued by the president. The time of interest is from 20-01-2001 to 20-01-2017 when George Bush and Barak Obama were in power.\n",
    "\n",
    "The aim of the study is to predict whether the 'final ruling' was issued during George Bush or Barak Obama tenure.This study will also have following activities:\n",
    "    #Download the data from Federal Registry API\n",
    "    #Parse the data\n",
    "    #Extract important features\n",
    "    #Apply NLP techniques to develop features from the abstract\n",
    "    #Develop a classification model that can predict whether the 'final ruling document' was issued by arak Obama or George Bush. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Information retrieval . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Maximum of 1000 documents can be downloaded from each API call. Therefore, 1000 most relevent documents were downloaded \n",
    "for each year\n",
    "8000 documents were downloaded for each president, Barak Obama and George Bush. \n",
    "It is expected that the dataset will have 16000 observations. The features will be created using LDA and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import json\n",
    "import urllib.request  as urllib2\n",
    "import json as JSON\n",
    "import os\n",
    "os.chdir(\"C://specdata/federal\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Functions used in the feature creation and parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Develop function for cleaning data.\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# List of words that is likely to appear frequently in the document\n",
    "words_to_remove=['Act', 'rule', 'document', 'regulation', 'new','changes','Commission','final','regulation',\n",
    "                'rules','order','federal']\n",
    "\n",
    "# Remove stopwords, tokenize and stemming\n",
    "def clean_my_data(letters):\n",
    "    clean_data=[]\n",
    "    for line in letters:\n",
    "        tokens = nltk.word_tokenize(str(line))\n",
    "        tagged = nltk.pos_tag(tokens)\n",
    "        container=[]\n",
    "        for words in tagged:\n",
    "            if (words[1][0] == 'N' or words[1][0]=='J') and (words[1][0] not in words_to_remove):\n",
    "                container.append(words[0])\n",
    "        clean_data.append(container)\n",
    "    return clean_data\n",
    "\n",
    "# LDA function (topic modelling)\n",
    "\n",
    "from gensim import corpora, models\n",
    "def topic_modelling(list_of_list):\n",
    "    dictionary = corpora.Dictionary(list_of_list)\n",
    "    corpus = [dictionary.doc2bow(text) for text in list_of_list]\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=2000, id2word = dictionary, passes=20)\n",
    "    topics = ldamodel.print_topics(num_topics=2000, num_words=3)\n",
    "    return topics\n",
    "\n",
    "# Abstract/title length calculator\n",
    "\n",
    "def length(list_of_content):\n",
    "    len_list=[]\n",
    "    for rows in list_of_content:\n",
    "        leng = len(rows) \n",
    "        len_list.append(leng)\n",
    "    return len_list\n",
    "\n",
    "\n",
    "#Function to extract agnecy name form the downloaded data. GAenct is used as a feature in classification model\n",
    "\n",
    "def extract_data_agency(agency_list):\n",
    "    raw_name_1=[]\n",
    "    \n",
    "    for dept in range(len(agency_list)):\n",
    "        raw_name_1.append(agency_list[dept][0]['raw_name'])\n",
    "    return raw_name_1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Download data from the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documents were downloaded from the API using urllib. For each call the API releases only 1000 documents. 16 different calls were made with 8000 for BO and 8000 for GB. The data was obtained in the form of json file, which was saved in the local disk. In the next step, the downloded json data is imported into this notebook for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#This code imports the downloaded data from the local drive and creates two different list. One for Barak Obama (BO)\n",
    "# and second for George Bush (GB)\n",
    "\n",
    "#Import and append data for BO\n",
    "\n",
    "BO_data_list=[]\n",
    "with open('BO_1.txt') as data_file_BO_1:    \n",
    "    BO_data_1 = json.load(data_file_BO_1)\n",
    "    BO_data_list.append(BO_data_1)\n",
    "\n",
    "with open('BO_2.txt') as data_file_BO_2:    \n",
    "    BO_data_2 = json.load(data_file_BO_2)\n",
    "    BO_data_list.append(BO_data_2)\n",
    "    \n",
    "with open('BO_3.txt') as data_file_BO_3:    \n",
    "    BO_data_3 = json.load(data_file_BO_3)\n",
    "    BO_data_list.append(BO_data_3)\n",
    "    \n",
    "with open('BO_4.txt') as data_file_BO_4:    \n",
    "    BO_data_4 = json.load(data_file_BO_4)\n",
    "    BO_data_list.append(BO_data_4)\n",
    "    \n",
    "with open('BO_5.txt') as data_file_BO_5:    \n",
    "    BO_data_5 = json.load(data_file_BO_5)\n",
    "    BO_data_list.append(BO_data_5)\n",
    "    \n",
    "with open('BO_6.txt') as data_file_BO_6:    \n",
    "    BO_data_6 = json.load(data_file_BO_6)\n",
    "    BO_data_list.append(BO_data_6)\n",
    "    \n",
    "with open('BO_7.txt') as data_file_BO_7:    \n",
    "    BO_data_7 = json.load(data_file_BO_7)\n",
    "    BO_data_list.append(BO_data_7)\n",
    "    \n",
    "with open('BO_8.txt') as data_file_BO_8:    \n",
    "    BO_data_8 = json.load(data_file_BO_8)\n",
    "    BO_data_list .append(BO_data_8)\n",
    "    \n",
    "print(len(BO_data_list))\n",
    "\n",
    "#Import and append data for GB\n",
    "    \n",
    "GB_data_list=[]\n",
    "with open('GB_1.txt') as data_file_GB_1:    \n",
    "    GB_data_1 = json.load(data_file_GB_1)\n",
    "    GB_data_list.append(GB_data_1)\n",
    "    \n",
    "with open('GB_2.txt') as data_file_GB_2:    \n",
    "    GB_data_2 = json.load(data_file_GB_2)\n",
    "    GB_data_list.append(GB_data_2)\n",
    "    \n",
    "with open('GB_3.txt') as data_file_GB_3:    \n",
    "    GB_data_3 = json.load(data_file_GB_3)\n",
    "    GB_data_list.append(GB_data_3)\n",
    "    \n",
    "with open('GB_4.txt') as data_file_GB_4:    \n",
    "    GB_data_4 = json.load(data_file_GB_4)\n",
    "    GB_data_list.append(GB_data_4)\n",
    "    \n",
    "with open('GB_5.txt') as data_file_GB_5:    \n",
    "    GB_data_5 = json.load(data_file_GB_5)\n",
    "    GB_data_list.append(GB_data_5)\n",
    "    \n",
    "with open('GB_6.txt') as data_file_GB_6:    \n",
    "    GB_data_6 = json.load(data_file_GB_6)\n",
    "    GB_data_list.append(GB_data_6)\n",
    "    \n",
    "with open('GB_7.txt') as data_file_GB_7:    \n",
    "    GB_data_7 = json.load(data_file_GB_7)\n",
    "    GB_data_list.append(GB_data_7)\n",
    "    \n",
    "with open('GB_8.txt') as data_file_GB_8:    \n",
    "    GB_data_8 = json.load(data_file_GB_8)\n",
    "    GB_data_list.append(GB_data_8)\n",
    "\n",
    "print(len(GB_data_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 LDA (Topic Modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As the first step, list of abstract is created for BO and GB. Subsquently, LDA is applied for each of this set separately. The topic and its probabilities are parsed and 6 feature sets are created with 3 topics and its probabilities. The two lists (Bo and GB) are merged to create a dataframe of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 LDA on the document abstract released during the term of Barak Obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "#Collect all the abstract for BO in the list 'abstract_list_1'\n",
    "abstract_list_1=[]\n",
    "for line1 in BO_data_list:\n",
    "    for line2 in line1['results']:\n",
    "        abstract_list_1.append(line2['abstract'])\n",
    "print(len(abstract_list_1))\n",
    "\n",
    "#This code will create a list of 8000 abstract for BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 153.04029750823975 seconds ---\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "# Clean the data, remove stopwords and punctuations use the function 'clean_my_data' , which was created earlier\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "BO_abs_clean_data = clean_my_data(abstract_list_1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(len(BO_abs_clean_data))\n",
    "\n",
    "# The output of this cell is the list of abstract without stop words. \n",
    "# This data is fed into LDA algorithm for topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:529: RuntimeWarning: overflow encountered in exp2\n",
      "  (perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words))\n",
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:700: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2781.64235496521 seconds ---\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# Out of the 8000 abstract (available in the abstract_list_1) 2000 abstracts are fed into the LDA model. \n",
    "# LDA modelling for the 2000 abstract takes around an hour. \n",
    "# Therefore, topic modelling of 16000 abstract will take 8 hours\n",
    "\n",
    "# LDA for first 2000 abstract of BO\n",
    "\n",
    "start_time = time.time()\n",
    "LDA_BO_1 = topic_modelling(BO_abs_clean_data[0:2000])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(len(LDA_BO_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:529: RuntimeWarning: overflow encountered in exp2\n",
      "  (perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words))\n",
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:700: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2693.0852675437927 seconds ---\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# LDA from 2000 to 4000 abstract of BO\n",
    "\n",
    "start_time = time.time()\n",
    "LDA_BO_2 = topic_modelling(BO_abs_clean_data[2000:4000])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(len(LDA_BO_1))\n",
    "print(len(LDA_BO_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:529: RuntimeWarning: overflow encountered in exp2\n",
      "  (perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words))\n",
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:700: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2650.5992753505707 seconds ---\n",
      "2000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# LDA from 4000 to 6000 abstract of BO\n",
    "start_time = time.time()\n",
    "LDA_BO_3 = topic_modelling(BO_abs_clean_data[4000:6000])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(len(LDA_BO_1))\n",
    "print(len(LDA_BO_2))\n",
    "print(len(LDA_BO_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:529: RuntimeWarning: overflow encountered in exp2\n",
      "  (perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words))\n",
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:700: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2680.826761484146 seconds ---\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# LDA from 6000 to 8000 abstract of BO\n",
    "start_time = time.time()\n",
    "LDA_BO_4 = topic_modelling(BO_abs_clean_data[6000:8000])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(len(LDA_BO_1))\n",
    "print(len(LDA_BO_2))\n",
    "print(len(LDA_BO_3))\n",
    "print(len(LDA_BO_4))\n",
    "\n",
    "#This completes the LDA modelling for 8000 BO abstract\n",
    "# Follow the same steps for topic modelling of abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "# Combine all the LDA list of BO\n",
    "\n",
    "LDA_BO=LDA_BO_1+LDA_BO_2+LDA_BO_3+LDA_BO_4\n",
    "print(len(LDA_BO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This list is saved in the local drive for future use\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('LDABO.csv', 'w') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(LDA_BO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.000*\"Free\" + 0.000*\"Class\" + 0.000*\"more\"')\n"
     ]
    }
   ],
   "source": [
    "print(LDA_BO[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 LDA on the document abstract released during the term of George Bush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "#Collect all the abstract for BO in the list 'abstract_list_1'\n",
    "\n",
    "abstract_list_2=[]\n",
    "for line3 in GB_data_list:\n",
    "    for line4 in line3['results']:\n",
    "        abstract_list_2.append(line4['abstract'])\n",
    "print(len(abstract_list_2))\n",
    "\n",
    "#This code will create a list of 8000 abstract for BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 155.92902660369873 seconds ---\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "# Clean the data, remove stopwords and punctuations use the function 'clean_my_data' , which was created earlier\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "GB_abs_clean_data = clean_my_data(abstract_list_2)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(len(GB_abs_clean_data))\n",
    "\n",
    "# The output of this cell is the list of abstract without stop words. \n",
    "# This data is fed into LDA algorithm for topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:529: RuntimeWarning: overflow encountered in exp2\n",
      "  (perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words))\n",
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:700: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2884.5209336280823 seconds ---\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# Out of the 8000 abstract (available in the abstract_list_2) 2000 abstracts are fed into the LDA model. \n",
    "# LDA modelling for the 2000 abstract takes around an hour. \n",
    "# Therefore, topic modelling of 16000 abstract will take 8 hours\n",
    "\n",
    "# LDA for first 2000 abstract of GB\n",
    "\n",
    "start_time = time.time()\n",
    "LDA_GB_1 = topic_modelling(GB_abs_clean_data[0:2000])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(len(LDA_BO_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:529: RuntimeWarning: overflow encountered in exp2\n",
      "  (perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words))\n",
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:700: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2694.336597919464 seconds ---\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# LDA from 2000 to 4000 abstract of GB\n",
    "\n",
    "start_time = time.time()\n",
    "LDA_GB_2 = topic_modelling(GB_abs_clean_data[2000:4000])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(len(LDA_GB_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:529: RuntimeWarning: overflow encountered in exp2\n",
      "  (perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words))\n",
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:700: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2629.2344963550568 seconds ---\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# LDA from 4000 to 6000 abstract of GB\n",
    "\n",
    "start_time = time.time()\n",
    "LDA_GB_3 = topic_modelling(GB_abs_clean_data[4000:6000])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(len(LDA_GB_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:529: RuntimeWarning: overflow encountered in exp2\n",
      "  (perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words))\n",
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:700: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2791.9896953105927 seconds ---\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# LDA from 6000 to 8000 abstract of GB\n",
    "\n",
    "start_time = time.time()\n",
    "LDA_GB_4 = topic_modelling(GB_abs_clean_data[6000:8000])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(len(LDA_GB_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine all the LDA list of GB\n",
    "LDA_GB= LDA_GB_1+ LDA_GB_2+ LDA_GB_3+ LDA_GB_4\n",
    "\n",
    "with open('LDAGB.csv', 'w') as myfile2:\n",
    "    wr = csv.writer(myfile2, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(LDA_GB)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combine the LDA list of GB and BO\n",
    "\n",
    "LDA= LDA_BO+LDA_GB\n",
    "\n",
    "\n",
    "with open('LDA.csv', 'w') as myfile3:\n",
    "    wr = csv.writer(myfile3, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(LDA) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA function generate 3 probable topics with its probability. This data is stored in the list 'LDA' in the form of tuple. The data from this tuple is parsed to generate 6 features consisting of three most probable topics and its three probabilities. The code below is used to generate these 6 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import LDA list from the drive\n",
    "\n",
    "import csv\n",
    "with open ('LDA.csv','r') as csvlist:\n",
    "    LDA_list= csv.reader(csvlist)\n",
    "    LDA =[]\n",
    "    for row in LDA_list:\n",
    "        LDA  = LDA +[row]\n",
    "csvlist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LDA= LDA[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parsing data to create features from topic and its probabilities\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "prob_1=[]\n",
    "prob_2=[]\n",
    "prob_3=[]\n",
    "topic_1=[]\n",
    "topic_2=[]\n",
    "topic_3=[]\n",
    "\n",
    "for prob in range(len(LDA)):\n",
    "    \n",
    "    probability= re.findall(r'\\d+', str(LDA[prob]))\n",
    "    pro_1 = float(probability[2])\n",
    "    prob_1.append(pro_1/1000)\n",
    "    pro_2= float(probability[4])\n",
    "    prob_2.append(pro_2/1000)\n",
    "    pro_3= float(probability[6])\n",
    "    prob_3.append(pro_3/1000)\n",
    "    \n",
    "    words = \" \".join(re.findall(\"[a-zA-Z]+\", str(LDA[prob])))\n",
    "    word= nltk.word_tokenize(str(words))\n",
    "    try: \n",
    "        topic_1.append(word[0])\n",
    "    except IndexError:\n",
    "        topic_1.append('NA')\n",
    "    try: \n",
    "        topic_2.append(word[1])\n",
    "    except IndexError:\n",
    "        topic_2.append('NA')\n",
    "    try: \n",
    "        topic_3.append(word[2])\n",
    "    except IndexError:\n",
    "        topic_3.append('NA')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create labels\n",
    "\n",
    "BO= [0]*8000\n",
    "GB= [1]*8000\n",
    "presi= BO+GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "\n",
    "DF= pd.DataFrame()\n",
    "#DF_GB= pd.DataFrame()\n",
    "DF['prob_1']= prob_1\n",
    "DF['prob_2']= prob_2\n",
    "DF['prob_3']= prob_3\n",
    "\n",
    "DF['abstract_topic_1']= topic_1\n",
    "DF['abstract_topic_2']= topic_2\n",
    "DF['abstract_topic_3']= topic_3\n",
    "\n",
    "DF['PRESIDENT']= presi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two dataframe to put togehter the features created till under BO and GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create other features (agency, significance and page length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other features are created directly by parsing the downloaded data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract agency data for BO\n",
    "\n",
    "agency_list=[]\n",
    "for objects in BO_data_list:\n",
    "    for element in objects['results']:\n",
    "        agency_BO = element['agencies']\n",
    "        agency_list.append(agency_BO)\n",
    "\n",
    "# Extract agency data for GB\n",
    "\n",
    "for objects2 in GB_data_list:\n",
    "    for element2 in objects2['results']:\n",
    "        agency_GB = element2['agencies']\n",
    "        agency_list.append(agency_GB)\n",
    "        \n",
    "#Agency list has 16000 entries for both BO and GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Agency list has several missing data which throws error message. \n",
    "# The following code is writtien to handle error exception and fill the missing values with 'NA'\n",
    "\n",
    "raw_name=[]\n",
    "for dept in range(len(agency_list)):\n",
    "    try:\n",
    "        raw_name.append(agency_list[dept][0]['raw_name'])\n",
    "    except IndexError:\n",
    "        raw_name.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append the Agency feature to the dataframe DF\n",
    "\n",
    "DF['Agency']=  raw_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note: 3 topic is not included in this data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a feature for document significance. This data is created by parsing the downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature: significance\n",
    "# Create an empty list to hold the 'Significance value'\n",
    "# For BO\n",
    "\n",
    "sign_list=[]\n",
    "for each in BO_data_list:\n",
    "    for sign in each['results']:\n",
    "        sign_BO = sign['significant']\n",
    "        sign_list.append(sign_BO)\n",
    "        \n",
    "        \n",
    "# For GB\n",
    "\n",
    "for lgb in GB_data_list:\n",
    "    for lenggb in lgb['results']:\n",
    "        pglen_GB = lenggb['page_length']\n",
    "        sign_list.append(pglen_GB)\n",
    "\n",
    "#Append the list to a new column in the dataframe\n",
    "\n",
    "DF['Significance']= sign_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature: page_length\n",
    "# Create an empty list to hold the 'Page Length'\n",
    "# For BO\n",
    "leng_list=[]\n",
    "for l in BO_data_list:\n",
    "    for leng in l['results']:\n",
    "        pglen_BO = leng['page_length']\n",
    "        leng_list.append(pglen_BO)\n",
    "        \n",
    "#For GB\n",
    "for lgb in GB_data_list:\n",
    "    for lenggb in lgb['results']:\n",
    "        pglen_GB = lenggb['page_length']\n",
    "        leng_list.append(pglen_GB)\n",
    "        \n",
    "#Append the list to a new column in the dataframe        \n",
    "\n",
    "DF['Page_length']= leng_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export the dataframe to local drive\n",
    "DF.to_csv('dataframe_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Create text features using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text features were created using CountVectorizer and TFIDF. Both the method created same number of features. In this study, TFIDF is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TFIDF features are created using the clean data, which was created in section 2.1.1 an 2.1.2 for BO abd GB together\n",
    "#BO clean data and GB clean data are merged together\n",
    "\n",
    "clean_data= BO_abs_clean_data+GB_abs_clean_data\n",
    "\n",
    "#TFIDF do not accept tokenized data. Therefore, clean_data is detokenized\n",
    "\n",
    "from nltk.tokenize.moses import MosesDetokenizer\n",
    "detokenizer = MosesDetokenizer()\n",
    "clean_data_detok=[]\n",
    "for it in range(len(clean_data)):\n",
    "    clean_data_detok.append(detokenizer.detokenize(clean_data[it], return_str=True))\n",
    "    \n",
    "# Empty values in the list are filled with 'This is empty list'\n",
    "\n",
    "for item in range(len(clean_data_detok)):\n",
    "    if not clean_data_detok[item]:\n",
    "        clean_data_detok[item]= 'This is empty list'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create features using Scikit Learn TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TFIDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv= TfidfVectorizer()\n",
    "vector_cv= cv.fit_transform(clean_data_detok)\n",
    "\n",
    "#Convert the numpy array into Dataframe\n",
    "count_stem_df= pd.DataFrame(vector_cv.toarray())\n",
    "\n",
    "#Add column Name\n",
    "count_stem_df.columns= cv.get_feature_names()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 24210)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The current shape of the dataframe is 16000 X 24210. There are too many columns in thi dataframe. \n",
    "# In next few steps, the dimension of the dataframe is reduced to a managable level.\n",
    "\n",
    "count_stem_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 22833)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Firs 1377 columns are numbers. Therefore, those are eliminated\n",
    "\n",
    "count_stem_df= count_stem_df.iloc[:, 1377: len(count_stem_df.columns)] \n",
    "count_stem_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'cols' isa empty list where column name are stored which are later dropped from the dataframe\n",
    "# In the first step, all the columns with just two alphabet are separated\n",
    "\n",
    "cols=[]\n",
    "for name in range(len(count_stem_df.columns)):\n",
    "    if len(count_stem_df.columns[name])<=2:\n",
    "        cols.append(count_stem_df.columns[name])\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1135"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All alphanumeric columns are separated\n",
    "\n",
    "for names in range(len(count_stem_df.columns)):\n",
    "    if count_stem_df.columns[names].isalpha()==False:\n",
    "        cols.append(count_stem_df.columns[names])\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 21753)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The column accumulated in 'cols' are dropped from dataframe. \n",
    "#After the dimension reduction, the shape of the dataframe is 16000 X 21753\n",
    "\n",
    "count_stem_df= count_stem_df.drop(cols, 1)\n",
    "count_stem_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5375\n",
      "(16000, 16378)\n"
     ]
    }
   ],
   "source": [
    "# Similar column names wre observed, such as abbreviate and abbreviation.\n",
    "# Therefore, column name in consecutive cell with more that 6 similar characters are removed\n",
    "\n",
    "same=[]\n",
    "for item in range(len(count_stem_df.columns)):\n",
    "    \n",
    "    if list(count_stem_df.columns[item][0:6])==list(count_stem_df.columns[item-1][0:6]):\n",
    "        same.append(count_stem_df.columns[item])\n",
    "        #print(A.columns[item],A.columns[item-1] )\n",
    "print(len(same))\n",
    "\n",
    "count_stem_df= count_stem_df.drop(same, 1)\n",
    "print(count_stem_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the dimension of the dataframe_2 is reduced from (16000, 24210) to (16000, 16378)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export dataframe to local drive\n",
    "count_stem_df.to_csv(\"dataframe_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two dataframes are created: (a) dataframe_1 with LDA features and (b) dataframe_2 with countvectorizer. Both the dataframes are stored in the local drive. In this next section, these two dataframes are imported and merged together. Various classification algorithms are then tested on this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section 2 has successfully created a dataframe consisting of features and label. In this section various classification model are applied to predict the president.\n",
    "Two different dataframes are imported from the local drive and merged to create a master data frame. The features and labels are then separated to create X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import dataframes \n",
    "\n",
    "data_1= pd.read_csv('dataframe_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import second dataframe\n",
    "\n",
    "data_2=pd.read_csv('dataframe_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge the two dataframe\n",
    "\n",
    "data = pd.concat([data_1, data_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Shuffle the dataset\n",
    "\n",
    "data= data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset index\n",
    "\n",
    "data= data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15512, 16390)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop missing values\n",
    "data= data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Encode categorical variables \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "data['Agency'] = lb_make.fit_transform(data[\"Agency\"])\n",
    "data['Significance'] = lb_make.fit_transform(data[\"Significance\"])\n",
    "data['abstract_topic_1'] = lb_make.fit_transform(data[\"abstract_topic_1\"])\n",
    "data['abstract_topic_2'] = lb_make.fit_transform(data[\"abstract_topic_2\"])\n",
    "data['abstract_topic_3'] = lb_make.fit_transform(data[\"abstract_topic_3\"])\n",
    "data['fitter']=data['fit']\n",
    "\n",
    "#Drop redundant columns. Column 'fit' has to be changed from 'fit' to 'fitter'. 'fit' throws an error.\n",
    "data = data.drop(['Unnamed: 0','fit'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The 'data' dataframe is too big and therefore it is divided into two equal dataframe\n",
    "# Each dataframe is used for prediction with 10 fold CV\n",
    "\n",
    "# create two sets\n",
    "df_1= data.iloc[:7756, :]\n",
    "df_2= data.iloc[7756:, :].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "      <th>prob_3</th>\n",
       "      <th>abstract_topic_1</th>\n",
       "      <th>abstract_topic_2</th>\n",
       "      <th>abstract_topic_3</th>\n",
       "      <th>PRESIDENT</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Significance</th>\n",
       "      <th>Page_length</th>\n",
       "      <th>...</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zoonotic</th>\n",
       "      <th>zte</th>\n",
       "      <th>zuchem</th>\n",
       "      <th>zuernii</th>\n",
       "      <th>zumwalt</th>\n",
       "      <th>zymed</th>\n",
       "      <th>zzz</th>\n",
       "      <th>fitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.143</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.039</td>\n",
       "      <td>3323</td>\n",
       "      <td>11</td>\n",
       "      <td>1975</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>1217</td>\n",
       "      <td>2567</td>\n",
       "      <td>3931</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>136</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1659</td>\n",
       "      <td>1152</td>\n",
       "      <td>3978</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.097</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.049</td>\n",
       "      <td>1388</td>\n",
       "      <td>401</td>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1650</td>\n",
       "      <td>3485</td>\n",
       "      <td>2670</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prob_1  prob_2  prob_3  abstract_topic_1  abstract_topic_2  \\\n",
       "0   0.143   0.079   0.039              3323                11   \n",
       "1   0.069   0.035   0.035              1217              2567   \n",
       "2   0.048   0.044   0.040              1659              1152   \n",
       "3   0.097   0.049   0.049              1388               401   \n",
       "4   0.000   0.000   0.000              1650              3485   \n",
       "\n",
       "   abstract_topic_3  PRESIDENT  Agency  Significance  Page_length   ...    \\\n",
       "0              1975          0      33           136            3   ...     \n",
       "1              3931          0      21           136           15   ...     \n",
       "2              3978          1      34            55            3   ...     \n",
       "3               639          1      34             0            1   ...     \n",
       "4              2670          1      24            36            2   ...     \n",
       "\n",
       "   zones  zoological  zoonotic  zte  zuchem  zuernii  zumwalt  zymed  zzz  \\\n",
       "0    0.0         0.0       0.0  0.0     0.0      0.0      0.0    0.0  0.0   \n",
       "1    0.0         0.0       0.0  0.0     0.0      0.0      0.0    0.0  0.0   \n",
       "2    0.0         0.0       0.0  0.0     0.0      0.0      0.0    0.0  0.0   \n",
       "3    0.0         0.0       0.0  0.0     0.0      0.0      0.0    0.0  0.0   \n",
       "4    0.0         0.0       0.0  0.0     0.0      0.0      0.0    0.0  0.0   \n",
       "\n",
       "   fitter  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "\n",
       "[5 rows x 16388 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop redundant columns\n",
    "\n",
    "df_2= df_2.drop(['level_0'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create X and Y for the set 1\n",
    "\n",
    "df_1_X= df_1.drop(['PRESIDENT'], axis=1)\n",
    "df_1_Y= df_1['PRESIDENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create X and Y for the set 2\n",
    "\n",
    "df_2_X= df_2.drop(['PRESIDENT'], axis=1)\n",
    "df_2_Y= df_2['PRESIDENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The performance metrices of various algorithm are stored in adataframe\n",
    "\n",
    "accuracy= pd.DataFrame()\n",
    "Algorith=[]\n",
    "Accuracy=[]\n",
    "Precision=[]\n",
    "Recall=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amar\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97683398  0.96267696  0.96525097  0.95741935  0.96129032  0.95612903\n",
      "  0.96129032  0.97032258  0.96645161  0.96645161] 0.964411674347\n",
      "[ 0.95609756  0.93111639  0.93556086  0.92216981  0.92874109  0.92\n",
      "  0.92874109  0.94444444  0.93764988  0.93764988] 0.934217101094\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.] 1.0\n",
      "--- 188.31600642204285 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# For the first set\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#Import packages\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "#fit the variables and calculate scores\n",
    "\n",
    "clf_nb = GaussianNB()\n",
    "clf_nb.fit(df_1_X, df_1_Y)\n",
    "score_nb=cross_val_score(clf_nb,df_1_X,df_1_Y, cv=10)\n",
    "scores_nb_precision = cross_val_score(clf_nb, df_1_X,df_1_Y, cv=10, scoring='precision')\n",
    "scores_nb_recall = cross_val_score(clf_nb, df_1_X,df_1_Y, cv=10, scoring='recall')\n",
    "\n",
    "\n",
    "print(score_nb, score_nb.mean())\n",
    "print(scores_nb_precision, scores_nb_precision.mean()) \n",
    "print(scores_nb_recall, scores_nb_recall.mean())\n",
    "\n",
    "Algorith.append('Naive Bayes')\n",
    "Accuracy.append(score_nb.mean())\n",
    "Precision.append(scores_nb_precision.mean())\n",
    "Recall.append(scores_nb_recall.mean())\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96778351  0.96907216  0.96778351  0.97551546  0.97680412  0.97680412\n",
      "  0.96903226  0.97806452  0.97290323  0.97806452] 0.973182740273\n",
      "[ 0.93990385  0.94216867  0.94202899  0.95365854  0.95599022  0.95599022\n",
      "  0.94202899  0.95823096  0.94890511  0.95823096] 0.94971364945\n",
      "[ 1.          1.          0.99744246  1.          1.          1.          1.\n",
      "  1.          1.          1.        ] 0.999744245524\n",
      "--- 178.52654719352722 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# For the second set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#Import packages\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "##fit the variables and calculate scores\n",
    "\n",
    "clf_nb_2 = GaussianNB()\n",
    "clf_nb_2.fit(df_2_X, df_2_Y)\n",
    "score_nb_2=cross_val_score(clf_nb_2,df_2_X,df_2_Y, cv=10)\n",
    "scores_nb_precision_2 = cross_val_score(clf_nb_2, df_2_X, df_2_Y, cv=10, scoring='precision')\n",
    "scores_nb_recall_2 = cross_val_score(clf_nb_2, df_2_X, df_2_Y, cv=10, scoring='recall')\n",
    "\n",
    "\n",
    "print(score_nb_2, score_nb_2.mean())\n",
    "print(scores_nb_precision_2, scores_nb_precision_2.mean()) \n",
    "print(scores_nb_recall_2, scores_nb_recall_2.mean())\n",
    "\n",
    "Algorith.append('Naive Bayes')\n",
    "Accuracy.append(score_nb_2.mean())\n",
    "Precision.append(scores_nb_precision_2.mean())\n",
    "Recall.append(scores_nb_recall_2.mean())\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56628057  0.68854569  0.55212355  0.53032258  0.88258065  0.55354839\n",
      "  0.59096774  0.60129032  0.57935484  0.58064516] 0.612565948437\n",
      "[ 0.67015707  0.58851675  0.87350835  0.55500821  0.53313253  0.54036244\n",
      "  0.70192308  0.83333333  0.85925926  0.52564103] 0.668084204137\n",
      "[ 0.71938776  0.92091837  0.30102041  0.86956522  0.96675192  0.65473146\n",
      "  0.69053708  0.69820972  0.71355499  0.26342711] 0.679810402422\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree for the first set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#fit the variables and calculate scores\n",
    "dc_1= DecisionTreeClassifier(max_features=50, max_depth=50, min_samples_split= 6)\n",
    "dc_1.fit(df_1_X, df_1_Y)\n",
    "\n",
    "scores_dc_1 = cross_val_score(dc_1, df_1_X, df_1_Y, cv=10)\n",
    "scores_dc_precision_1 = cross_val_score(dc_1, df_1_X, df_1_Y, cv=10, scoring='precision')\n",
    "scores_dc_recall_1 = cross_val_score(dc_1,df_1_X, df_1_Y, cv=10, scoring='recall')\n",
    "\n",
    "print(scores_dc_1, scores_dc_1.mean())\n",
    "print(scores_dc_precision_1, scores_dc_precision_1.mean()) \n",
    "print(scores_dc_recall_1, scores_dc_recall_1.mean())\n",
    "\n",
    "Algorith.append('Decision Tree')\n",
    "Accuracy.append(scores_dc_1.mean())\n",
    "Precision.append(scores_dc_precision_1.mean())\n",
    "Recall.append(scores_dc_recall_1.mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52963918  0.58247423  0.53608247  0.54510309  0.9935567   0.53092784\n",
      "  0.74322581  0.55870968  0.54709677  0.57806452] 0.614488027935\n",
      "[ 0.69607843  0.96954315  0.74358974  0.52723312  0.6377551   0.5643739\n",
      "  0.54731861  0.55368421  0.99222798  0.54299363] 0.677479786975\n",
      "[ 0.93350384  0.86700767  0.35805627  0.90025575  0.62404092  0.22250639\n",
      "  0.58205128  0.28205128  0.78717949  0.22564103] 0.578229392091\n",
      "--- 46.83039903640747 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree for second set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#fit the variables and calculate scores\n",
    "dc_2= DecisionTreeClassifier(max_features=50, max_depth=50, min_samples_split= 6)\n",
    "dc_2.fit(df_2_X, df_2_Y)\n",
    "\n",
    "scores_dc_2 = cross_val_score(dc_2, df_2_X, df_2_Y, cv=10)\n",
    "scores_dc_precision_2 = cross_val_score(dc_2, df_2_X, df_2_Y, cv=10, scoring='precision')\n",
    "scores_dc_recall_2 = cross_val_score(dc_2,df_2_X, df_2_Y, cv=10, scoring='recall')\n",
    "\n",
    "print(scores_dc_2, scores_dc_2.mean())\n",
    "print(scores_dc_precision_2, scores_dc_precision_2.mean()) \n",
    "print(scores_dc_recall_2, scores_dc_recall_2.mean())\n",
    "\n",
    "Algorith.append('Decision Tree')\n",
    "Accuracy.append(scores_dc_2.mean())\n",
    "Precision.append(scores_dc_precision_2.mean())\n",
    "Recall.append(scores_dc_recall_2.mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93178893  0.94079794  0.94980695  0.85290323  0.98064516  0.9083871\n",
      "  0.95483871  0.96258065  0.97677419  0.99612903] 0.945465188691\n",
      "[ 0.9389313   0.99230769  0.95384615  0.93417722  0.96969697  0.96428571\n",
      "  0.97721519  0.95607235  0.95454545  0.97953964] 0.962061768082\n",
      "[ 0.94897959  0.93112245  0.95153061  0.89258312  0.96675192  0.97186701\n",
      "  0.96163683  0.91815857  0.97442455  0.95140665] 0.946846129756\n",
      "--- 166.6035225391388 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier for the first set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#fit the variables and calculate scores\n",
    "\n",
    "RF_1 = RandomForestClassifier(n_estimators=100,criterion='entropy', max_features= 50, max_depth= 50, min_samples_leaf= 6 )\n",
    "RF_1.fit( df_1_X, df_1_Y)\n",
    "\n",
    "scores_RF_1 = cross_val_score(RF_1, df_1_X, df_1_Y, cv=10)\n",
    "scores_RF_precision_1 = cross_val_score(RF_1, df_1_X, df_1_Y, cv=10, scoring='precision')\n",
    "scores_RF_recall_1 = cross_val_score(RF_1,  df_1_X, df_1_Y, cv=10, scoring='recall')\n",
    "\n",
    "print(scores_RF_1, scores_RF_1.mean())\n",
    "print(scores_RF_precision_1, scores_RF_precision_1.mean()) \n",
    "print(scores_RF_recall_1, scores_RF_recall_1.mean())\n",
    "\n",
    "Algorith.append('Random Forest')\n",
    "Accuracy.append(scores_RF_1.mean())\n",
    "Precision.append(scores_RF_precision_1.mean())\n",
    "Recall.append(scores_RF_recall_1.mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93685567  0.99226804  0.96907216  0.97680412  0.97293814  0.96134021\n",
      "  0.97806452  0.91483871  0.96        0.97677419] 0.963895576987\n",
      "[ 0.98982188  0.9278607   0.89252336  0.96725441  0.93638677  0.98457584\n",
      "  0.98477157  0.97974684  0.96401028  1.        ] 0.962695164776\n",
      "[ 0.88491049  0.98209719  0.98465473  0.98721228  0.96675192  0.98209719\n",
      "  0.97435897  0.98974359  0.92051282  0.94358974] 0.961592891337\n",
      "--- 169.62343311309814 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier for the second set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#fit the variables and calculate scores\n",
    "RF_2 = RandomForestClassifier(n_estimators=100,criterion='entropy', max_features= 50, max_depth= 50, min_samples_leaf= 6 )\n",
    "RF_2.fit( df_2_X, df_2_Y)\n",
    "\n",
    "scores_RF_2 = cross_val_score(RF_2, df_2_X, df_2_Y, cv=10)\n",
    "scores_RF_precision_2 = cross_val_score(RF_2, df_2_X, df_2_Y, cv=10, scoring='precision')\n",
    "scores_RF_recall_2 = cross_val_score(RF_2, df_2_X, df_2_Y, cv=10, scoring='recall')\n",
    "\n",
    "print(scores_RF_2, scores_RF_2.mean())\n",
    "print(scores_RF_precision_2, scores_RF_precision_2.mean()) \n",
    "print(scores_RF_recall_2, scores_RF_recall_2.mean())\n",
    "\n",
    "Algorith.append('Random Forest')\n",
    "Accuracy.append(scores_RF_2.mean())\n",
    "Precision.append(scores_RF_precision_2.mean())\n",
    "Recall.append(scores_RF_recall_2.mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.998713    0.93564994  0.62805663  0.9883871   0.66451613  0.92774194\n",
      "  0.98709677  0.92903226  0.59225806  0.61419355] 0.826564536887\n",
      "[ 0.60046189  0.60628019  0.6047619   0.6185567   0.94458438  0.89928058\n",
      "  0.92821782  0.58956916  0.92118227  0.64646465] 0.735935954646\n",
      "[ 0.9872449   0.98469388  0.71683673  0.7084399   0.94629156  0.62659847\n",
      "  0.65217391  0.7314578   0.94373402  0.9488491 ] 0.824632026724\n",
      "--- 265.147762298584 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting for the first set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#fit the variables and calculate scores\n",
    "\n",
    "gb_1= GradientBoostingClassifier(n_estimators=100, min_samples_split=7,max_features= 50)\n",
    "gb_1.fit(df_1_X, df_1_Y)\n",
    "\n",
    "scores_gb_1 = cross_val_score(gb_1, df_1_X, df_1_Y, cv=10)\n",
    "scores_gb_precision_1 = cross_val_score(gb_1, df_1_X, df_1_Y, cv=10, scoring='precision')\n",
    "scores_gb_recall_1 = cross_val_score(gb_1, df_1_X, df_1_Y, cv=10, scoring='recall')\n",
    "\n",
    "print(scores_gb_1, scores_gb_1.mean())\n",
    "print(scores_gb_precision_1, scores_gb_precision_1.mean()) \n",
    "print(scores_gb_recall_1, scores_gb_recall_1.mean())\n",
    "\n",
    "Algorith.append('Gradient Boost')\n",
    "Accuracy.append(scores_gb_1.mean())\n",
    "Precision.append(scores_gb_precision_1.mean())\n",
    "Recall.append(scores_gb_recall_1.mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91494845  0.95876289  0.63530928  0.95103093  0.60824742  1.\n",
      "  0.95870968  0.96        0.97935484  0.60774194] 0.857410542069\n",
      "[ 0.6027088   0.58872651  0.60580913  0.94513716  0.93939394  0.59832636\n",
      "  0.63466667  0.58314351  0.97727273  0.63043478] 0.710561958667\n",
      "[ 0.69565217  0.96930946  0.73401535  0.64705882  0.65217391  0.95396419\n",
      "  0.97435897  0.94615385  0.57179487  0.98717949] 0.813166109253\n",
      "--- 264.18249917030334 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting for the second set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#fit the variables and calculate scores\n",
    "\n",
    "gb_2= GradientBoostingClassifier(n_estimators=100, min_samples_split=7,max_features= 50)\n",
    "gb_2.fit(df_2_X, df_2_Y)\n",
    "\n",
    "scores_gb_2 = cross_val_score(gb_2, df_2_X, df_2_Y, cv=10)\n",
    "scores_gb_precision_2 = cross_val_score(gb_2, df_2_X, df_2_Y, cv=10, scoring='precision')\n",
    "scores_gb_recall_2 = cross_val_score(gb_2, df_2_X, df_2_Y, cv=10, scoring='recall')\n",
    "\n",
    "print(scores_gb_2, scores_gb_2.mean())\n",
    "print(scores_gb_precision_2, scores_gb_precision_2.mean()) \n",
    "print(scores_gb_recall_2, scores_gb_recall_2.mean())\n",
    "\n",
    "Algorith.append('Gradient Boost')\n",
    "Accuracy.append(scores_gb_2.mean())\n",
    "Precision.append(scores_gb_precision_2.mean())\n",
    "Recall.append(scores_gb_recall_2.mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.] 1.0\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.] 1.0\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.] 1.0\n",
      "--- 61.5029878616333 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost for first set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#fit the variables and calculate scores\n",
    "\n",
    "ab_1= AdaBoostClassifier(algorithm= 'SAMME', n_estimators=100, learning_rate=1)\n",
    "ab_1.fit(df_1_X, df_1_Y)\n",
    "\n",
    "scores_ab_1 = cross_val_score(ab_1, df_1_X, df_1_Y, cv=10)\n",
    "scores_ab_precision_1 = cross_val_score(ab_1, df_1_X, df_1_Y, cv=10, scoring='precision')\n",
    "scores_ab_recall_1 = cross_val_score(ab_1, df_1_X, df_1_Y, cv=10, scoring='recall')\n",
    "\n",
    "print(scores_ab_1, scores_ab_1.mean())\n",
    "print(scores_ab_precision_1, scores_ab_precision_1.mean()) \n",
    "print(scores_ab_recall_1, scores_ab_recall_1.mean())\n",
    "\n",
    "Algorith.append('AdaBoost')\n",
    "Accuracy.append(scores_ab_1.mean())\n",
    "Precision.append(scores_ab_precision_1.mean())\n",
    "Recall.append(scores_ab_recall_1.mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          1.          0.99871134  1.          1.          1.          1.\n",
      "  1.          1.          1.        ] 0.999871134021\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.] 1.0\n",
      "[ 1.          1.          0.99744246  1.          1.          1.          1.\n",
      "  1.          1.          1.        ] 0.999744245524\n",
      "--- 61.530038595199585 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost for the second set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#fit the variables and calculate scores\n",
    "\n",
    "ab_2= AdaBoostClassifier(algorithm= 'SAMME', n_estimators=100, learning_rate=1)\n",
    "ab_2.fit(df_2_X, df_2_Y)\n",
    "\n",
    "scores_ab_2 = cross_val_score(ab_2,df_2_X, df_2_Y, cv=10)\n",
    "scores_ab_precision_2 = cross_val_score(ab_2, df_2_X, df_2_Y, cv=10, scoring='precision')\n",
    "scores_ab_recall_2 = cross_val_score(ab_2, df_2_X, df_2_Y, cv=10, scoring='recall')\n",
    "\n",
    "print(scores_ab_2, scores_ab_2.mean())\n",
    "print(scores_ab_precision_2, scores_ab_precision_2.mean()) \n",
    "print(scores_ab_recall_2, scores_ab_recall_2.mean())\n",
    "\n",
    "Algorith.append('AdaBoost')\n",
    "Accuracy.append(scores_ab_2.mean())\n",
    "Precision.append(scores_ab_precision_2.mean())\n",
    "Recall.append(scores_ab_recall_2.mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.] 1.0\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.] 1.0\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.] 1.0\n",
      "--- 2446.1845536231995 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# XGboost for the first set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#fit the variables and calculate scores\n",
    "\n",
    "xg_1= XGBClassifier(base_score=0.5,learning_rate=0.1,max_depth=50, n_estimators=100)\n",
    "xg_1.fit(df_1_X, df_1_Y)\n",
    "\n",
    "scores_xg_1 = cross_val_score(xg_1, df_1_X, df_1_Y, cv=10)\n",
    "scores_xg_precision_1 = cross_val_score(xg_1,df_1_X, df_1_Y, cv=10, scoring='precision')\n",
    "scores_xg_recall_1 = cross_val_score(xg_1, df_1_X, df_1_Y, cv=10, scoring='recall')\n",
    "\n",
    "print(scores_xg_1, scores_xg_1.mean())\n",
    "print(scores_xg_precision_1, scores_xg_precision_1.mean()) \n",
    "print(scores_xg_recall_1, scores_xg_recall_1.mean())\n",
    "\n",
    "Algorith.append('XGBoost')\n",
    "Accuracy.append(scores_xg_1.mean())\n",
    "Precision.append(scores_xg_precision_1.mean())\n",
    "Recall.append(scores_xg_recall_1.mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          1.          0.99871134  1.          1.          1.          1.\n",
      "  1.          1.          1.        ] 0.999871134021\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.] 1.0\n",
      "[ 1.          1.          0.99744246  1.          1.          1.          1.\n",
      "  1.          1.          1.        ] 0.999744245524\n",
      "--- 2818.3103935718536 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# XGboosting for the second set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "xg_2= XGBClassifier(base_score=0.5,learning_rate=0.1,max_depth=50, n_estimators=100)\n",
    "xg_2.fit(df_2_X, df_2_Y)\n",
    "scores_xg_2 = cross_val_score(xg_2, df_2_X, df_2_Y, cv=10)\n",
    "scores_xg_precision_2 = cross_val_score(xg_2, df_2_X, df_2_Y, cv=10, scoring='precision')\n",
    "scores_xg_recall_2 = cross_val_score(xg_2, df_2_X, df_2_Y, cv=10, scoring='recall')\n",
    "print(scores_xg_2, scores_xg_2.mean())\n",
    "print(scores_xg_precision_2, scores_xg_precision_2.mean()) \n",
    "print(scores_xg_recall_2, scores_xg_recall_2.mean())\n",
    "Algorith.append('XGBoost')\n",
    "Accuracy.append(scores_xg_2.mean())\n",
    "Precision.append(scores_xg_precision_2.mean())\n",
    "Recall.append(scores_xg_recall_2.mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Algorith  Accuracy  Precision    Recall\n",
      "0      Naive Bayes  0.964412   0.934217  1.000000\n",
      "1      Naive Bayes  0.973183   0.949714  0.999744\n",
      "2    Decision Tree  0.612566   0.668084  0.679810\n",
      "3    Decision Tree  0.614488   0.677480  0.578229\n",
      "4    Random Forest  0.945465   0.962062  0.946846\n",
      "5    Random Forest  0.963896   0.962695  0.961593\n",
      "6   Gradient Boost  0.826565   0.735936  0.824632\n",
      "7   Gradient Boost  0.857411   0.710562  0.813166\n",
      "8         AdaBoost  1.000000   1.000000  1.000000\n",
      "9         AdaBoost  0.999871   1.000000  0.999744\n",
      "10         XGBoost  1.000000   1.000000  1.000000\n",
      "11         XGBoost  0.999871   1.000000  0.999744\n"
     ]
    }
   ],
   "source": [
    "# Dataframe showing the performance metrices of the algorithms\n",
    "accuracy['Algorith']= Algorith\n",
    "accuracy['Accuracy']= Accuracy\n",
    "accuracy['Precision']= Precision\n",
    "accuracy['Recall']= Recall\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The boosting algorithm has shown a promising performance to accurately classifiy the observations. The AdaBoost and XG Boost, both have 100% acuracy, precision and recall score. Random Forest and Naive Bayes have also shown good results, however the medal goes to boosting algorith. \n",
    "\n",
    "### This exercise has also demonstrated that the LDA and TFIDF can create good feature set for classifiying or clustering the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chellanges faced:\n",
    "\n",
    "### The maximum of 1000 documents could be downloaded for each year,  which made the code long\n",
    "### LDA is a time consuming process. It takes an hour to model topic of 2000 documents. Perhaps, different packages must be tested for speed\n",
    "### TFIDF and CountVectorize produced same number of features. Generally it is expected that TFIDF will produce less features than CV because it eliminates unnecessary words\n",
    "### The final data set was too big to run. It was divided into two dataframe and tested separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
